---
title: "Borges y el tango" 
author:  "Germán Rosati (CONICET - IDAES/UNSAM - PIMSA)"
#bibliography: biblio.bib
#csl: apa.csl
output: html_notebook
---
 
## Introducción
Hacia fines del 2019 organizamos en UNSAM un [taller sobre _text mining_ y _natural language processing_](https://gefero.github.io/ws_text_mining). En esa ocasión presentamos una idea de aplicación de topic modeling sobre letras de tango. 

La idea era poder detectar de forma automática los temas de los que habla el tango. Como era de esperar, hay mucha literatura al respecto (por ejemplo [acá](http://webs.ucm.es/info/especulo/numero45/mutango.html), [acá](https://dialnet.unirioja.es/servlet/articulo?codigo=5215965), [acá](https://dialnet.unirioja.es/servlet/articulo?codigo=5959025) o [acá](http://www.dariocanton.com/template.php?file=publicaciones/sociologia/1972_gardel-a-quien-le-cantas.html)). Pero en general la mayoría parece emplear un enfoque "manual", lo cual redunde en

1. dificultad para establecer criterios claros para la confección del corpus
2. el tamaño de los corpus es entre pequeño (10 tangos) y moderado (100 tangos)
3. con la excepción del texto de [Cantón](http://www.dariocanton.com/template.php?file=publicaciones/sociologia/1972_gardel-a-quien-le-cantas.html), los textos son abordados a partir del rastreo de un tópico o pregunta particular en profundidad, privilegiándose un análisis interpretativo del contenido.

Es por eso que nos pareció que la utilización de 



> “el tango, como hemos visto, empezó, surge de la milonga, y es al principio un baile valeroso y feliz. Y luego, el tango va languideciendo y entristeciéndose..."


Ahora bien, podemos 


## 3. Construcción del corpus y flujo de trabajo

El corpus fue construido a partir del scraping de todas las letras de tango disponibles en el sitio [todo tango](www.todotango.com). 

Además de las letras se descargó información accesoria sobre el tango en cuestión. Para ello se confeccionaron dos web crawlers sencillos^[El código puede ser consultado en nuestro repositorio http://www.github/gefero.]. 

El corpus final consiste en alrededor de 5200 letras de tango. 
Si bien existen múltiples formas de llegar a una [representación vectorial](https://towardsdatascience.com/different-techniques-to-represent-words-as-vectors-word-embeddings-3e4b9ab7ceb4) del corpus $C$, optamos por utilizar el [modelo _Bag of Words_ ($BoW$)](https://en.wikipedia.org/wiki/Bag-of-words_model), manteniendo solamente el conteo crudo de frecuencias de las palabras ($c(t, d)$) como métrica. El preprocesamiento realizado para este corpus fue el siguiente:

1. normalización a minúsculas
2. eliminación de _stopwords_
3. elimnación de puntuación y 
4. eliminación de caracteres extraños y dígitos


## 4. Detección de tópicos

Para el presente trabajo se utilizará una de las más conocidas: _Latent Dirichlet Allocation_ o LDA. Existen numerosos [papers](http://www.cs.columbia.edu/~blei/papers/Blei2012.pdf) y [tutoriales](https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158) al respecto, pero la intuición fundamental detrás de LDA es que cada documento del corpus puede exhibir varios tópicos, es decir, puede hablar de varios temas simultáneamente. 

Por ejemplo, al analizar un tango como “Malena” de Homero Manzi, se observa que habla de diferentes temas: del amor, del tango, del barrio, etc. La idea detrás de LDA es poder operacionalizar esta intuición a través de un modelo generativo, es decir, asume la existencia de un “proceso generador de textos”.

Un tópico no es otra cosa que una distribución de probabilidad sobre un vocabulario $V$ fijo. Por ejemplo, si existiera un tópico como sentimientos palabras como “amor”, “pena”, “sufrimiento”, deberían tener altas probabilidades para este tópico. En cambio, palabras como “ciudad”, “barrio” estarían más asociadas a un tópico acerca de la ciudad.

Ahora bien, para cada documento $d$ en el corpus $C$ se generan las palabras $w$ que lo componen en un proceso de dos etapas:

1. Se selecciona de forma aleatoria una distribución de tópicos para $d$
2. Para cada palabras ($w$) en $d$
   i) Se selecciona aleatoriamente un tópico de la distribución general de tópicos 
   ii) Se selecciona aleatoriamente una palabra correspondiente a la distribución de todo el vocabulario $V$

Ahora bien, el método utilizado tiene algunas supuestos que, si bien pueden deducirse de lo expuesto más arriba, será útil repasarlos:

1. Cada documento $d$ se compone de varios tópicos
2. Un tópico está formado por palabras: es una distribución de probabilidad sobre la totalidad de palabras del vocabulario $V$
3. Los tópicos “preexisten” a los documentos
4. Dado que se basa en el modelo $BoW$ se asume que las palabras no tienen orden
5. No importa el orden de los documentos. 

Se asume que existe una cantidad fija de tópicos (y que es un hiperparámetro del modelo). Esto puede ser un problema al analizar corpus con documentos de épocas muy diferentes. Hay flexibilizaciones de este supuesto en los llamados [_dynamic topic models_](https://en.wikipedia.org/wiki/Dynamic_topic_model).



## Ok, pero ¿de qué catzo habla el tango? Algunos resultados

Veamos, entonces... un primer problema es tunear el hiperparámetro fundamental: la cantidad $k$ de tópicos a detectar. Este problema es análogo al problema de determinación de la cantidad de clusters al aplicar algoritmos de segmentación tales como _K-means_. Existen diversas métricas para "medir" el ajuste, pero en este caso (como en muchas situaciones de análisis de datos) todo depende de lo que se busca. En términos generales, un número de tópicos grande tiende a arrojar mejores métricas y tiende a permitir una alta resolución de la estructura latente del corpus.

Un primer rasgo que puede observarse es que, independientemente de las inicializaciones, existen algunos tópicos que se mantienen:

* Sentimientos y emociones con carácter positivo o negativo
* Imágenes de la noche, oscuridad y sombras asociadas a despedidas
* Imágenes que vinculan al tango y al barrio, arrabal
* Tópico sobre el tango, específicamente

Hemos llamado "misceláneos" a aquellos tópicos que presentan una distribución de palabras que no resultan interpretables. 

**Gráfico 1. Compisición de las 30 palabras de cada tópico ($k=12$)**

```{r echo=FALSE, fig.height=15, fig.width=15, message=FALSE, warning=FALSE}
library(ggwordcloud)
topic_names_12_06<-c('01 Imagenes climaticas', 
               '02 Ciudad, imagenes urbanas', 
               '03 Misc',
               '04 Emociones positivas', 
               '05 Campo y gauchesca',
               '06 Tango y arrabal',
               '07 Tiempo, recuerdos', 
               '08 Misc',
               '09 Emociones negativas',
               '10 Candombe',
               '11 Misc y familia',
               '12 Misc y lunfardo')


topic_terms<-list()
for (t in 1:12){
        topic_terms[[t]] <- get_topic_terms(lda=lda, topic_n=t, n_words = 30)
}

topic_terms <- do.call(rbind, topic_terms)

names(topic_names_12_06)<-1:12

topic_terms %>%
        ggplot(aes(label=term, size=prob, color=prob)) +
        geom_text_wordcloud(rm_outside = TRUE) +
        scale_size_area(max_size=25) +
        scale_fill_viridis_c() +
        facet_wrap(~topic, labeller= as_labeller(topic_names_12_06)) + 
        theme_minimal()
```

Puede verse que el primer tópico detectado tiene palabras como "noche", "luna", "cielo", "sombras", "viento". Es decir, nos habla de _imágenes naturales o climáticas_.

A su vez, el segundo tópico capta el tema de la _ciudad y de las imágenes urbanas_: menciona términos como "buenos", "aires", "ciudad", "calles". El tópico 6 habla del _arrabal, pero sobre todo del tango mismo_ ("tango", "barrio", "arrabal", "canción", "milonga", "bandonéon"). El tópico 7 ("pasado", "recuerdo", "tiempo") menciona palabras vinculadas al paso del _tiempo y a la memoria_.

Los tópicos 4 y 9 contienen palabras vinculadas a las _emociones_. El 4 ("ilusión", "pasión", "corazón", "amor") con una connotación positiva y el 9 ("amor", "dolor", "pena", "triste"), negativa.

El tópico 5 y el 10 logran evidenciar tópicos de carácter "étnico", por decirlo de alguna manera: el 5 con palabras como "china", "gaucho", "tierra", "sangre" capta la cuestión de la _gauchesca y el campo_. El tópico 10, en cambio, ("carnaval", "negro", "morena", "candombe") habla sobre el _candombe y la cuestión de color_.

Por último, restan cuatro tópicos. Dos de ellos (3 y 8) tienen un carácter residual. Resultan difíciles de interpretar, por ello fueron etiquetados como _miscélaneos_. No obstante, el 11 y el 12, si bien contienen muchos términos que son poco interpetables, puede verse que el 11 ("vieja, "domingo", "niños") contiene palabras vinculadas a la _vida familiar_ y el 12, términos en _lunfardo_ ("bulín, "pinta", "che", "pibe). El tópico 12, también parece tener como sus dos palabras más importantes "vos" y "sos", con lo cual, parece estar captando el hecho de que se habla de _forma directa a un interlocutor_.

**Tabla 3. Identificación de los tópicos hallados**

| Tópico | Etiqueta |
|--------|----------|
| 01 | Imagenes climaticas      |
| 02 | Ciudad, imagenes urbanas |
| 04 | Emociones positivas      |
| 05 | Campo y gauchesca        |
| 06 | Tango y arrabal          |
| 07 | Tiempo, recuerdos        |
| 09 | Emociones negativas      |
| 10 | Candombe                 |
| 11 | Misc y familia           |
| 12 | Misc y lunfardo          |


Ahora que hemos logrado interpretar los tópicos podemos pasar a poner a prueba la hipótesis de _Georgie_. Para eso, analicemos la evolución de cada uno de los tópicos a lo largo de las diferentes décadas.

**Gráfico 4. Evolución de los tópicos, 1900-2010 (suavizado GAM)**

```{r echo=FALSE, fig.height=8, fig.width=10, message=FALSE, warning=FALSE}

df %>%
        select(decada, ano) %>%
        bind_cols(., as.data.frame(doc_topics)) %>%
        gather(topic, value, `01 Imagenes climaticas`:`12 Misc y lunfardo`) %>%
        ggplot() +
                #geom_point(aes(x=ano, y=value, color=topic)) +
                geom_smooth(aes(x=ano, y=value, color=topic)) +
                facet_wrap(~topic) +
                theme_minimal() +
                theme(legend.position = 'none')
```


A partir de la evolución temporal puede verse cómo efectivamente van modificándose los temas del tango. En primer lugar, las imágenes naturales y climáticas ganan predominio de forma casi sostenida a lo largo del tiempo. En mucha menor medida, el tópico vinculado a la ciudad parece ganar cierta importancia a partir de la década del '30. También resultan interesantes las oscilaciones que parece presentar el tema del tango y el arrabal. Parece caer levemente hacia la década del '20 y vuelve a incrementarse hacia los años '50, mostrando otro valle hacia los años '70.

Pero quizás uno de los cambios más importantes es el que se observa en los tópicos 4 y 9. En efecto, puede verse que la participación de las emociones positivas es relativamente constante a lo largo del tiempo. En cambio, son las emociones negativas las que muestran diferencias fundamentales a lo largo del tiempo: muestran una tendencia al crecimiento hasta la década del '40-'50 y luego tienden a bajar de forma más suave.

De esta forma, puede verse que esta hipótesis parece ser corroborada por la información construida. En el mismo texto, Borges  discute sobre las causas de dicho cambio: explora hipótesis cuasi-sociológicas sobre la influencia negra, la italiana y otras hipótesis musicológicas, tales como la importancia de la introducción del bandoneón.

A partir de las series anteriores podrían plantearse preguntas que interroguen sobre la vinculación existente entre éstos cambios en los temas del tango u los procesos de desarrollo y expansión del capitalismo en Argentina y/o a los procesos de migración rural-urbana. 

También es posible calcular la composición promedio de los diferentes tópicos en cada autor de tango. A continuación, desplegamos la composición de los cinco autores con mayor cantidad de letras en el dataset.



## 6. Resultados y discusión

En el presente trabajo se buscó presentar una aproximación metodológica posible para el análisis automático de textos a partir de la aplicación de una técnica de detección de tópicos (LDA) sobre un dataset de 5.600 letras de tango. A su vez, se presentó un flujo de trabajo posible para dicho análisis y se discutieron algunas técnicas para el preprocesamiento del texto.

De esta forma, fue posible estimar, mediante la técnica de topic modeling LDA, los principales temas del tango. Así, el uso de emociones positivas y negativas, imágenes de la ciudad, sobre el tango y el arrabal, sobre el campo y la gauchesca, sobre la temporalidad y la memoria, entre otros, aparecían como los más importantes. Al mismo tiempo, fue posible validar los tópicos a partir de la selección de algunos tangos y del análisis de sus letras buscando su correspondencias con los tópicos estimados.

Quizás uno de las posibilidades analíticas más interesantes fue la de poder visualizar la evolución temporal de los tópicos y, eventualmente, plantear hipótesis sobre la vinculación con procesos más generales y vinculados a otras dimensiones analíticas por fuera de las determinaciones internas del género tango (procesos vinculados a los cambios en la estructura económica, migratorios, etc.).

Finalmente, fue posible analizar las diferencias (distancias) entre los tópicos utilizados por diferentes autores.

Ahora bien, más allá de los resultados del ejercicio propuesto (que tienen como objetivo más mostrar un caso de uso de la herramienta que agotar las determinaciones del objeto en cuestión), el trabajo busca mostrar las potencialidades que este tipo de técnicas tienen para la investigación en ciencias sociales. Así, con una herramienta que permita analizar con un corpus amplio y de forma sistemática la evolución de los temas del tango (u otros géneros), sería posible vincular analítica y metodológicamente la dimensión cultural con otras esferas de la estructura social^[Como hemos mencionado más arriba, uno de los supuestos de LDA en su versión básica, es que los tópicos preexisten a los textos y son constantes en el tiempo. Se trata de un supuesto fuerte para un análisis temporal. Es por ello que existen otras versiones de modelado de tópicos que permiten flexibilizar estos supuestos: _Dynamic topic modeling_, por ejemplo [@blei1].].

Al mismo, la detección de tópicos ha sido utilizada en los últimos tiempos para el análisis literario [@jockers], el estudio de comunicados políticos [@grimmer2], el estudio de medios [@wind, @blei2], el estudio de temas en leyes y proyectos [@blei3], por nombrar algunas aplicaciones relevantes.

En efecto, sus principales ventajas radican en su escalabilidad y replicabilidad: utilizando las técnicas de análisis cualitativo de textos "tradicionales", es posible lograr gran profundidad analítica pero sobre corpus más bien pequeños o medianos y escasamente replicables. Así, los trabajos mencionados tenían una escala más bien pequeña: alrededor de 30 letras de tango. La excepción es el trabajo de Cantón [-@canton]. El proceso de detección de tópicos encarado en el presente trabajo procesó y analizó una base de datos de alrededor de 6.200 letras de tango.

A su vez, el uso de técnicas automáticas de NLP no implica un desplazamiento de los enfoques tradicionales. Un buen ejemplo es el trabajo de Baumer y otros [-@baumer], en el que se comparan los resultados obtenidos utilizando dos métodos de análisis sobre un mismo corpus de datos: generación de categorías utilizando la metodología de la _Grounded Theory_ y detección de tópicos utilizando LDA. Los resultados sugieren tanto una coherencia como una complementariedad entre los resultados de ambos métodos.


# Anexo - Tablas con los primeros 8 términos para estimación de tópicos con diferentes $k$.

**Tabla A.1 $k$=15** 
```{r echo=FALSE, fig.height=15, fig.width=15, message=FALSE, warning=FALSE}

knitr::kable(terms(lda_list[[2]],8) %>% t() %>% as_tibble() %>% mutate(topic=paste('Topic',1:15)) %>% select(topic, everything()))
```

**Tabla A.2 $k$=13**
```{r echo=FALSE, fig.height=15, fig.width=15, message=FALSE, warning=FALSE}

knitr::kable(terms(lda_list[[6]],8) %>% t() %>% as_tibble() %>% mutate(topic=paste('Topic',1:13)) %>% select(topic, everything()))
```

**Tabla A.1 $k$=10**
```{r echo=FALSE, fig.height=15, fig.width=15, message=FALSE, warning=FALSE}

knitr::kable(terms(lda_list[[12]],8) %>% t() %>% as_tibble() %>% mutate(topic=paste('Topic',1:10)) %>% select(topic, everything()))
```

**Tabla A.1 $k$=5**
```{r echo=FALSE, fig.height=15, fig.width=15, message=FALSE, warning=FALSE}

knitr::kable(terms(lda_list[[22]],8) %>% t() %>% as_tibble() %>% mutate(topic=paste('Topic',1:5)) %>% select(topic, everything()))
`
